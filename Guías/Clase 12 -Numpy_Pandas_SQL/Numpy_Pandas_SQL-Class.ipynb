{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guía Data Science - Numpy, Pandas, SQL\n",
    "\n",
    "En esta guía veremos algunos conceptos básicos que se necesitan para el manejo de datos. Comenzaremos con una pequeña introducción a ``numpy``, luego aprenderemos un poco sobre ``pandas`` y finalmente utilizaremos datos externos y los procesaremos con SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Te recomendamos correr este notebook en google colab para que no tengas que instalar nada en tu computador. Para subir los archivos `comunas.db` y `Resultados_Pleb.csv` que utilizaremos más adelante de la siguiente forma: \n",
    "\n",
    "- Si los tienes descargados, puedes subirlos en la sección de Archivos (hay un ícono de carpeta en el menú del lado izquierdo).\n",
    "- Si no los tienes descargados, puedes acceder a los archivos en github utilizando el siguiente comando en una celda del notebook:\n",
    "```\n",
    "!wget  [link a github donde se encuentra el archivo]\n",
    "```\n",
    "Por ejemplo\n",
    "```\n",
    "!wget  https://github.com/IIC2413/Syllabus-2021-2/raw/main/clases/comunas.db\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumPy` es una librería para hacer computos numéricos en Python y la necesitamos conocer (en concreto, el manejo de arreglos) para poder entender el funcionamiento de `pandas`. Es la base de muchas otras librerías científicas. Entre otras cosas, nos permite:\n",
    "\n",
    "- Utilizar arreglos multidimensionales.\n",
    "- Utilizar funciones matemáticas.\n",
    "- Utilizar herramientas de álgebra lineal.\n",
    "\n",
    "Para comenzar a trabajar vamos a importar la librería y crear un pequeño arreglo de elementos aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(2,4)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de una lista, podemos hacer operaciones matriciales, como multiplicar el arreglo `data` por un escalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o sumarle una matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data + data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos crear arreglos a partir de una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 1, 2, 3, 5]\n",
    "arr1 = np.array(list1)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = [[1, 1, 2, 3], [5, 8, 13, 21]]\n",
    "arr2 =np.array(list2)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para preguntar el número de dimensiones en un arreglo utilizamos `ndim` y para preguntar los tamaños de cada una de esas dimensiones utilizamos `shape` (por ejemplo, pensar en arr2 como una matriz de 2 x 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acceder a un elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos acceder de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y los arreglos son mutables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[1, 2] = 100\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También tenemos un equivalente a `range` llamado `arange`, pero que genera un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, también podemos utilizar comparaciones booleanas con los arreglos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0, 0, 1, 1, 2, 2])\n",
    "arr == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de esta comparación punto a punto es un arreglo de valores booleanos. Este arreglo se puede usar para acceder a valores en otros arreglos, de forma que solo nos quedamos con los valores indicados como *true*. Vamos a crear un arreglo multidimensional e ingresar el arreglo anterior como índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.random.randn(6, 3)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entoncers me voy a quedar con las filas 2 y 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[arr == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también podemos negar la condición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[~(arr == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A los arreglos booleanos, comunmente se les llama máscaras (_boolean mask_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta segunda parte estudiaremos la herramienta de análisis de datos `pandas`, una librería que permite hacer análisis y limpieza de datos en Python. Está diseñada para trabajar con datos tabulares y heterogéneos. También es utilizada en conjunto con otras herramientas para hacer *Data Science* como `NumPy`, `SciPy`, `matplotlib` y `scikit-learn`.\n",
    "\n",
    "Partimos importando la librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Series\n",
    "\n",
    "Vamos a partir instanciando objetos de tipo `Series`. Estos objetos son como arreglos unidimensionales, solo que su índice es más explícito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([1, 3, -4, 7])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(['asdsa', 3, -4, 7])\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un objeto de tipo `Series` podemos agregar un label a sus índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([1, 3, -4, 7], index=['d', 'c', 'b', 'a'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar varios elementos según el label de su índice o su posición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[['c', 'a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer filtros pasando un arreglo de *booleanos*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[obj > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos lo que significaba la comparación `obj > 2` en `NumPy`. Genera una máscara con el mismo largo que `obj` que tenía el valor `True` en todas las posiciones con valor mayor a 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj > 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que en `obj[obj > 2]` se muestran sólo las filas en la que el arreglo anterior era `True`.\n",
    "\n",
    "Finalmente, podemos crear un objeto `Series` a partir de un diccionario. Supongamos el siguiente diccionario de personas junto a su edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = {'Alice': 20, 'Bob': 17, 'Charles': 23, 'Dino': 50}\n",
    "people_series = pd.Series(people)\n",
    "people_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DataFrame\n",
    "\n",
    "Un objeto de tipo `DataFrame` representa una tabla, en que cada una de sus columnas tiene un tipo. Vamos a construir una tabla a partir de un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_chile = {'name': ['Metropolitana', 'Valparaiso', 'Biobío', 'Maule', 'Araucanía', 'O\\'Higgins'],\n",
    "             'pop': [7112808, 1815902, 1538194, 1044950, 957224, 914555],\n",
    "             'pib': [24850, 14510, 13281, 12695, 11064, 14840]}\n",
    "frame = pd.DataFrame(reg_chile)\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar la función `head` para tener sólo las 5 primeras columnas del Data Frame. En este caso no es mucho aporte, pero para un Data Frame más grande no puede servir para ver cómo vienen los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos proyectar valores pasando el nombre de las columnas que deseamos dejar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['name', 'pop']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar una determinada fila con la función `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar la misma idea de filtros vista anteriormente. Por ejemplo, vamos a dejar sólamente las columnas con población mayor a 1.000.000. ¿Te suena esto a algún otro lenguaje que viste este semestre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame['pop'] > 1000000] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer filtros con `&` para hacer un `AND`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[(frame['pop'] > 1000000) & (frame['pib'] < 20000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos usar `|` para hacer un `OR`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[(frame['name'] == 'Metropolitana') | (frame['name'] == 'Valparaiso')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ordenar un objeto `DataFrame` usamos la función `sort_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_values(by='pib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_values(by='pib', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si necesitamos ordenar por más de una columna, podemos pasar un arreglo al argumento `by`. Existen muchas formas de crear y operar sobre un `DataFrame`. Puedes revisar la documentación para encontrar más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería `pandas` tiene varias funciones que nos permiten obtener descripciones y resúmenes de los datos. Vamos a ver algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos datos de verdad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos cargar datos de un csv de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Resultados_Pleb.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes pasarle como argumento `sep=algun_string` para cambiar el separador del csv. Por ejemplo si el archivo tuviera separación con `;`, podrías hacer algo como:\n",
    "\n",
    "```py\n",
    "df = pd.read_csv('Resultados_Pleb.csv', sep=';') \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos quiséramos quedar con algunas columnas, pero no queremos hacer cambios permanentes, podemos guardar la información en un nuevo dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['cod_com', 'Apruebo']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero si quisiéramos cambiar el dataframe de forma permanente podemos hacerlo así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['cod_com', 'Apruebo']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando cargas datos desde un csv, puede que quieras saber los tipos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen algunos comandos que puedes buscar para pasar datos que son string a números, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilizando datos externos y SQL\n",
    "\n",
    "Para analizar datos y aprender como trabajar con SQL, usaremos la base de datos `comunas.db` que usa el siguiente esquema: \n",
    "\n",
    "```\n",
    "Comunas(cod INT PRIMARY KEY, \n",
    "        nombre VARCHAR(200), \n",
    "        provincia VARCHAR(200), \n",
    "        region VARCHAR(200), \n",
    "        superficie FLOAT, \n",
    "        poblacion INT, \n",
    "        densidad FLOAT, \n",
    "        idh FLOAT)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('comunas.db')\n",
    "conn.text_factory = lambda x: str(x, 'utf-8')\n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos realizado la conexión,  usaremos una consulta SQL para extraer los datos y guardarlos en un dataframe. Comúnmente la idea es preparar los datos con SQL y extraer a pandas solo lo necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.execute(\"SELECT * FROM Comunas;\")\n",
    "com_frame = pd.DataFrame(curr.fetchall())\n",
    "com_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombremos los nombres de las columnas del dataframe según nuestro esquema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.rename(columns = { 0: 'cod', 1: 'nombre', 2: 'provincia', 3: 'region', \n",
    "                            4: 'superficie', 5: 'poblacion', 6: 'densidad', 7: 'idh'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos `head` y `describe` para tener una mejor idea de como se ven nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tabla tenemos valores nulos. Vamos a buscarlos. Primero vamos a encontrar todas las filas que contengan algún nulo, para luego filtrar por ese arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame[com_frame.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` tiene métodos auxiliares para lidiar con datos faltantes. Uno es eliminar aquellas filas con la función `dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_cleaned = com_frame.dropna()\n",
    "com_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O podemos tomar una opción menos radical, que es reemplazar los nulos por un valor en particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame = com_frame.fillna(0)\n",
    "com_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchas otras opciones para limpiar los datos, pero no son parte de esta guía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, veamos algunos ejemplos de agregación de datos utilizando `pandas`. Lo primero que haremos será cambiar el nombre de las columnas del Data Frame con método diferente al que utilizamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.columns = ['cod', 'nombre', 'prov', 'reg', 'sup', 'pobl', 'dens', 'idh']\n",
    "com_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la cantidad de habitantes por región haremos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame['pobl'].groupby(com_frame['reg']).sum() # Ojo! esto retorna un objeto Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos preguntar cuántos elementos hay por grupo. En este caso obtendríamos el número de comunas por región."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame['pobl'].groupby(com_frame['reg']).count() # Ojo! esto retorna un objeto Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos hacer varias agregaciones a la vez, retornando un solo data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.groupby(['reg']).agg({'idh': ['mean', 'std'], 'dens':['mean', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando de arriba retorna un df multi nivel :O! los cuales son un poco más complejos de trabajar.\n",
    "\n",
    "Como pueden ver en `pandas` se pueden hacer operaciones mucho más complejas, pero no veremos nada avanzado en esta ocasión. Puedes revisar la documentación para ver que más puedes hacer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agregar columnas al df basadas en las otras columnas mediante el método `apply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame['computed_density'] = com_frame.apply(lambda row: row.pobl / row.sup, axis=1)\n",
    "com_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame['computed_density_ez'] = com_frame['pobl'] / com_frame['sup']\n",
    "com_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame['computed_density_ez'] = com_frame.pobl / com_frame.sup\n",
    "com_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede hacer merge (join) de dos dataframes de la siguiente forma:\n",
    "\n",
    "```py\n",
    "df = df1.merge(df2, left_on='atributo_df1', right_on='atributo_df2')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las ventajas de trabajar con `pandas` es que tenemos acceso rápido a herramientas de visualización. Vamos a ver un ejemplo rápido, haciendo un gráfico para ver la correlación entre superficie y población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.plot.scatter(x='sup', y='pobl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos limpiar los _outliers_ (datos muy alejados de lo \"normal\") para ver mejor el gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame[(com_frame['sup'] < 20000) & (com_frame['pobl'] < 50000)].plot.scatter(x='sup', y='pobl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos calcular correlación entre las columnas que tengan valores numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_frame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = com_frame[['sup', 'pobl']]\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asd",
   "language": "python",
   "name": "asd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
